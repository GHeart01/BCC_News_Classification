{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfe2c44f",
   "metadata": {},
   "source": [
    "# Limitation of sklearnâ€™s non-negative matrix factorization library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b741cffb",
   "metadata": {},
   "source": [
    "Upload a Jupyter notebook with a mix of code/markdown to answer the following questions. Please mark the sections of your notebook as 1 and 2 so that graders can follow along."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3781e6-c5a7-4585-a353-fef5396393ab",
   "metadata": {},
   "source": [
    "\n",
    "#### Table of Contents\n",
    "\n",
    "- [Part 1](#Part-1)\n",
    "- [Part 2](#Part-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a40e60c-28e2-4e8d-9223-80df53798ed3",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d4d5e5-0855-473d-be23-9d3414db0fcc",
   "metadata": {},
   "source": [
    "1. Load the movie ratings data (as in the HW3-recommender-system) and use matrix factorization technique(s) and predict the missing ratings from the test data. Measure the RMSE. You should use sklearn library. [10 pts]\n",
    "\n",
    "Make sure that your notebook includes the following: use's sklearn's non-negative matrix factorization ,notebook shows the RMSE with an analysis of what that RMSE means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc0e88c-85d6-4577-b54b-14b4cfad86d6",
   "metadata": {},
   "source": [
    "### 1. Use Matrix Factorization Techniques and Predict the Missing Ratings from the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c5abb6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9046b7c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns: ['uID', 'mID', 'rating']\n",
      "Test columns: ['uID', 'mID', 'rating']\n"
     ]
    }
   ],
   "source": [
    "# Load the movie ratings data from module 3\n",
    "users = pd.read_csv('data/users.csv')\n",
    "movies = pd.read_csv('data/movies.csv')\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(\"Train columns:\", train.columns.tolist())\n",
    "print(\"Test columns:\", test.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa63426-faba-4773-8e4e-d270a8416b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDataset Overview:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain\u001b[49m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumber of users: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(users)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'train' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Overview:\")\n",
    "print(f\"Training samples: {len(train)}\")\n",
    "print(f\"Test samples: {len(test)}\")\n",
    "print(f\"Number of users: {len(users)}\")\n",
    "print(f\"Number of movies: {len(movies)}\")\n",
    "print(f\"Rating range: {train['rating'].min()} - {train['rating'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301cab70-b640-46b8-8670-92ac081a284b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sparsity: 97.01%\n"
     ]
    }
   ],
   "source": [
    "# Check for data sparsity\n",
    "total_possible_ratings = len(users) * len(movies)\n",
    "actual_ratings = len(train)\n",
    "sparsity = (1 - actual_ratings / total_possible_ratings) * 100\n",
    "print(f\"Data sparsity: {sparsity:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8320e116-ef1c-47f6-aad3-0eea97b12949",
   "metadata": {},
   "source": [
    "Here we have a high sparsity, which is normal, but the method filling missing values will likely change RMSE a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8daa54-16e5-4f17-8b56-ae8f3e0d7f12",
   "metadata": {},
   "source": [
    "### Creating the User Item Rating Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8350172e-66cc-4b07-923c-5c1715b8f187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-item matrix shape: (6040, 3883)\n",
      "Non-zero entries: 700146\n",
      "23453320\n"
     ]
    }
   ],
   "source": [
    "# Create user-item matrix from training data\n",
    "def create_user_item_matrix(ratings_df, users_df, movies_df):\n",
    "    \"\"\"\n",
    "    Create a user-item rating matrix from the ratings dataframe\n",
    "    \"\"\"\n",
    "    # Create mappings for user and movie IDs to matrix indices\n",
    "    user_to_idx = {user_id: idx for idx, user_id in enumerate(users_df['uID'])}\n",
    "    movie_to_idx = {movie_id: idx for idx, movie_id in enumerate(movies_df['mID'])}\n",
    "    \n",
    "    # Create the matrix\n",
    "    n_users = len(users_df)\n",
    "    n_movies = len(movies_df)\n",
    "    \n",
    "    user_item_matrix = np.zeros((n_users, n_movies))\n",
    "    \n",
    "    for _, row in ratings_df.iterrows():\n",
    "        user_idx = user_to_idx[row['uID']]\n",
    "        movie_idx = movie_to_idx[row['mID']]\n",
    "        user_item_matrix[user_idx, movie_idx] = row['rating']\n",
    "    \n",
    "    return user_item_matrix, user_to_idx, movie_to_idx\n",
    "\n",
    "# Create the training matrix\n",
    "train_matrix, user_to_idx, movie_to_idx = create_user_item_matrix(train, users, movies)\n",
    "print(f\"User-item matrix shape: {train_matrix.shape}\")\n",
    "print(f\"Non-zero entries: {np.count_nonzero(train_matrix)}\")\n",
    "print(train_matrix.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7550e65-f004-4d3d-88a8-d7c5ba8729d0",
   "metadata": {},
   "source": [
    "Once again high sparsity is comfirmed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de69b7be-2f41-44d7-8796-6a05c50c1e3d",
   "metadata": {},
   "source": [
    "### Applying NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7148d739-3437-4c5c-bc9d-471db357352d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing NMF with 10 components...\n",
      "Training RMSE: 3.3515\n",
      "\n",
      "Testing NMF with 25 components...\n",
      "Training RMSE: 3.3515\n",
      "\n",
      "Testing NMF with 50 components...\n",
      "Training RMSE: 3.3515\n",
      "\n",
      "Testing NMF with 100 components...\n",
      "Training RMSE: 3.3515\n"
     ]
    }
   ],
   "source": [
    "# Apply NMF to the user-item matrix\n",
    "def apply_nmf(matrix, n_components=50, random_state=42):\n",
    "    \"\"\"\n",
    "    Apply Non-Negative Matrix Factorization to the user-item matrix\n",
    "    \"\"\"\n",
    "    # Convert to sparse matrix for efficiency\n",
    "    sparse_matrix = csr_matrix(matrix)\n",
    "    \n",
    "    # Initialize and fit NMF model\n",
    "    nmf_model = NMF(\n",
    "        n_components=n_components,\n",
    "        random_state=random_state,\n",
    "        init='random',\n",
    "        max_iter=500,\n",
    "        alpha_W=0.1,\n",
    "        alpha_H=0.1,\n",
    "        l1_ratio=0.0\n",
    "    )\n",
    "    \n",
    "    # Fit the model (only on non-zero entries)\n",
    "    W = nmf_model.fit_transform(matrix)\n",
    "    H = nmf_model.components_\n",
    "    \n",
    "    # Reconstruct the full matrix\n",
    "    reconstructed_matrix = np.dot(W, H)\n",
    "    \n",
    "    return nmf_model, W, H, reconstructed_matrix\n",
    "\n",
    "# Apply NMF with different numbers of components\n",
    "n_components_list = [10, 25, 50, 100]\n",
    "results = {}\n",
    "\n",
    "for n_comp in n_components_list:\n",
    "    print(f\"\\nTesting NMF with {n_comp} components...\")\n",
    "    nmf_model, W, H, reconstructed = apply_nmf(train_matrix, n_components=n_comp)\n",
    "    \n",
    "    # Calculate reconstruction error on training data (only for non-zero entries)\n",
    "    mask = train_matrix > 0\n",
    "    train_rmse = sqrt(mean_squared_error(\n",
    "        train_matrix[mask], \n",
    "        reconstructed[mask]\n",
    "    ))\n",
    "    \n",
    "    results[n_comp] = {\n",
    "        'model': nmf_model,\n",
    "        'W': W,\n",
    "        'H': H,\n",
    "        'reconstructed': reconstructed,\n",
    "        'train_rmse': train_rmse\n",
    "    }\n",
    "    \n",
    "    print(f\"Training RMSE: {train_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2813303-a6e0-4914-ab5b-90b446ecb864",
   "metadata": {},
   "source": [
    "### Making Prediction on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9494725f-586f-4d89-b4c4-8acbb7b39d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation:\n",
      "==================================================\n",
      "NMF with 10 components:\n",
      "  Test RMSE: 2.7743\n",
      "  Training RMSE: 3.3515\n",
      "\n",
      "NMF with 25 components:\n",
      "  Test RMSE: 2.7743\n",
      "  Training RMSE: 3.3515\n",
      "\n",
      "NMF with 50 components:\n",
      "  Test RMSE: 2.7743\n",
      "  Training RMSE: 3.3515\n",
      "\n",
      "NMF with 100 components:\n",
      "  Test RMSE: 2.7743\n",
      "  Training RMSE: 3.3515\n",
      "\n",
      "Best performance: 100 components with RMSE = 2.7743\n"
     ]
    }
   ],
   "source": [
    "def predict_test_ratings(test_df, reconstructed_matrix, user_to_idx, movie_to_idx):\n",
    "    \"\"\"\n",
    "    Predict ratings for test data using the reconstructed matrix\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    actual_ratings = []\n",
    "    \n",
    "    for _, row in test_df.iterrows():\n",
    "        user_id = row['uID']\n",
    "        movie_id = row['mID']\n",
    "        actual_rating = row['rating']\n",
    "        \n",
    "        # Get indices\n",
    "        if user_id in user_to_idx and movie_id in movie_to_idx:\n",
    "            user_idx = user_to_idx[user_id]\n",
    "            movie_idx = movie_to_idx[movie_id]\n",
    "            \n",
    "            predicted_rating = reconstructed_matrix[user_idx, movie_idx]\n",
    "            \n",
    "            # Clip predictions to valid rating range\n",
    "            predicted_rating = np.clip(predicted_rating, 1, 5)\n",
    "            \n",
    "            predictions.append(predicted_rating)\n",
    "            actual_ratings.append(actual_rating)\n",
    "        else:\n",
    "            # Handle users/movies not in training data with global mean\n",
    "            global_mean = train['rating'].mean()\n",
    "            predictions.append(global_mean)\n",
    "            actual_ratings.append(actual_rating)\n",
    "    \n",
    "    return np.array(predictions), np.array(actual_ratings)\n",
    "\n",
    "# Evaluate all models on test data\n",
    "print(\"Test Set Evaluation:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "best_rmse = float('inf')\n",
    "best_n_components = None\n",
    "\n",
    "for n_comp in n_components_list:\n",
    "    predictions, actual = predict_test_ratings(\n",
    "        test, \n",
    "        results[n_comp]['reconstructed'], \n",
    "        user_to_idx, \n",
    "        movie_to_idx\n",
    "    )\n",
    "    \n",
    "    test_rmse = sqrt(mean_squared_error(actual, predictions))\n",
    "    results[n_comp]['test_rmse'] = test_rmse\n",
    "    results[n_comp]['predictions'] = predictions\n",
    "    results[n_comp]['actual'] = actual\n",
    "    \n",
    "    print(f\"NMF with {n_comp} components:\")\n",
    "    print(f\"  Test RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"  Training RMSE: {results[n_comp]['train_rmse']:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    if test_rmse < best_rmse:\n",
    "        best_rmse = test_rmse\n",
    "        best_n_components = n_comp\n",
    "\n",
    "print(f\"Best performance: {best_n_components} components with RMSE = {best_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea86357c-de4e-414a-80f2-8d43ace490d1",
   "metadata": {},
   "source": [
    "### RMSE Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adedce9-3376-43a3-a63a-a0c8f90393a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Analysis:\n",
      "Best Test RMSE: 2.7743\n",
      "\n",
      "NMF improvement over baseline: -119.5\n"
     ]
    }
   ],
   "source": [
    "best_model = results[best_n_components]\n",
    "\n",
    "print(\"RMSE Analysis:\")\n",
    "\n",
    "print(f\"Best Test RMSE: {best_rmse:.4f}\")\n",
    "print()\n",
    "\n",
    "baseline_rmse = 1.264\n",
    "print(f\"NMF improvement over baseline: {((baseline_rmse - best_rmse) / baseline_rmse * 100):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c754705e-0d85-408d-bc86-898f3413e931",
   "metadata": {},
   "source": [
    "Here we see that the best RMSE is 2.774, which is very poor, and represent a high prediction error. This is likely due to substiting 0 for null/empty values. Considering RMSE/4 * 100 should represent what the error is relative to the 1-5 range for our scoring system for movies; the error here is 69%. This represents a extreme decline in performance in NMF over a baseline of 1.264 (From module 3) of 119.5%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfac3f9-fb5f-4427-85b4-5cccf326beb5",
   "metadata": {},
   "source": [
    "## Part 2 \n",
    "Analysis of Result and Limitations\n",
    "\n",
    "Discuss the results and why sklearn's non-negative matrix facorization library did not work well compared to simple baseline or similarity-based methods weâ€™ve done in Module 3. Can you suggest a way(s) to fix it? [10 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c51b84-2959-47e9-921e-dbd4f4c05fdf",
   "metadata": {},
   "source": [
    "The performance of sklearn's NMF is extremely poor in comparision to Module 3 Assignment performance. I achieved and RMSE score of 2.774 which is worse than every baseline, collaborative and jaccard method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4680cb7-b547-4a0d-af8d-074a6b922a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Mean Baseline RMSE: 1.2640\n",
      "Original Best NMF RMSE:    2.7743\n",
      "Improved NMF RMSE:         2.7276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def improved_nmf(matrix, n_components=50):\n",
    "    \"\"\"\n",
    "    NMF with stronger regularization and better init\n",
    "    \"\"\"\n",
    "    nmf_improved = NMF(\n",
    "        n_components=20,     # Try more factors\n",
    "        init='nndsvda',\n",
    "        solver='mu',         # Try the other solver\n",
    "        max_iter=2000,\n",
    "        alpha_W=0.05,        # Slightly lighter regularization\n",
    "        alpha_H=0.05,\n",
    "        l1_ratio=0.1,\n",
    "        beta_loss='frobenius',\n",
    "        random_state=42\n",
    "    )\n",
    "    return nmf_improved\n",
    "\n",
    "# === Train Improved NMF ===\n",
    "nmf_model_improved = improved_nmf(train_matrix, n_components=best_n_components)  # reuse best n_components\n",
    "\n",
    "W_improved = nmf_model_improved.fit_transform(train_matrix)\n",
    "H_improved = nmf_model_improved.components_\n",
    "\n",
    "reconstructed_improved = np.dot(W_improved, H_improved)\n",
    "\n",
    "# === Predict test ratings ===\n",
    "predictions_improved, actual_improved = predict_test_ratings(\n",
    "    test,\n",
    "    reconstructed_improved,\n",
    "    user_to_idx,\n",
    "    movie_to_idx\n",
    ")\n",
    "\n",
    "improved_rmse = sqrt(mean_squared_error(actual_improved, predictions_improved))\n",
    "\n",
    "\n",
    "print(f\"Global Mean Baseline RMSE: {baseline_rmse:.4f}\")\n",
    "print(f\"Original Best NMF RMSE:    {best_rmse:.4f}\")\n",
    "print(f\"Improved NMF RMSE:         {improved_rmse:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77783fe1-0e4f-470e-88a8-14c10d7c9fc9",
   "metadata": {},
   "source": [
    "#### Improved NMSE!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74700642-c15a-4048-89e2-84bb49b5a02b",
   "metadata": {},
   "source": [
    "Through some hypertuning I was able to slighly improve the performance of the NMF method. Albeit not by much. NMF did not perform well compared to baseline methods as sklearn.NMF does not support missing data, and treats 0s as real data points despite our scale being 1-5. From the EDA we can see the data is mostly empty. Global baseline mean makes no assumptions and just uses overall average. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312246a4-60f3-4e79-ae60-8ddbf0fcd7b1",
   "metadata": {},
   "source": [
    "Can you suggest a way(s) to fix it?\n",
    "\n",
    "The simplest answer is not the use sklearn.NMF, alternatively I could attmept something like jaccard method where I subsitute all missing values for the median in the range of values. I think the best solution here is to use a different library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30418d0",
   "metadata": {},
   "source": [
    "|Method|RMSE|\n",
    "|:----|:--------:|\n",
    "|Baseline, $Y_p$=3| 1.264|\n",
    "|Baseline, $Y_p=\\mu_u$| 1.035|\n",
    "|Content based, item-item| 1.0128|\n",
    "|Collaborative, cosine| 1.0263|\n",
    "|Collaborative, jaccard, $M_r\\geq 3$| 0.9819 |\n",
    "|Collaborative, jaccard, $M_r\\geq 1$|  0.9914|\n",
    "|Collaborative, jaccard, $M_r$|  0.9509|\n",
    "|NMF| 2.7743 |\n",
    "|NMF improved| 2.7276 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d572a31c-1eb1-4b10-8629-c1cd65fb5624",
   "metadata": {},
   "source": [
    "Here I have added to the chart from module 3 our new RMSE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
